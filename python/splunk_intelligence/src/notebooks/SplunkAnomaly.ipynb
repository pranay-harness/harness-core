{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, 'plots')\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "from core.Tokenizer import Tokenizer\n",
    "from core.TFIDFVectorizer import TFIDFVectorizer\n",
    "from sources.SplunkFileSource import SplunkFileSource\n",
    "from core.KmeansCluster import KmeansCluster\n",
    "from core.KmeansAnomalyDetector import KmeansAnomalyDetector\n",
    "from core.IsolationForestClassifier import IsolationForestClassifier\n",
    "\n",
    "import plotly as py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plot as plot\n",
    "\n",
    "py.offline.init_notebook_mode()\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "data_sources_names = []\n",
    "\n",
    "data_source_picker = None\n",
    "time_range_picker = None\n",
    "event_picker = None\n",
    "event_text_area = None \n",
    "threshold_picker = None\n",
    "new_time_range_picker = None\n",
    "\n",
    "#create widgets\n",
    "def create_widgets():\n",
    "    global data_source_picker, time_range_picker, event_picker\n",
    "    global event_text_area, threshold_picker, new_time_range_picker\n",
    "    for file in os.listdir(\"../../data\"):\n",
    "            if file.endswith(\".json\"):\n",
    "                data_sources_names.append(file)\n",
    "\n",
    "    data_source_picker = widgets.Dropdown(\n",
    "            options=data_sources_names,\n",
    "            description='Data Source:',\n",
    "            disabled=False,\n",
    "            button_style='' # 'success', 'info', 'warning', 'danger' or ''\n",
    "        )    \n",
    "\n",
    "    time_range_picker = widgets.IntRangeSlider(\n",
    "                value=[1, 2],\n",
    "                min=0,\n",
    "                max=100,\n",
    "                step=1,\n",
    "                description='Control Time:',\n",
    "                disabled=False,\n",
    "                continuous_update=False,\n",
    "                orientation='horizontal',\n",
    "                readout=True,\n",
    "                readout_format='i',\n",
    "                slider_color='white',\n",
    "                color='black'\n",
    "        )\n",
    "    \n",
    "    new_time_range_picker = widgets.IntRangeSlider(\n",
    "                value=[1, 2],\n",
    "                min=0,\n",
    "                max=100,\n",
    "                step=1,\n",
    "                description='Test Time:',\n",
    "                disabled=False,\n",
    "                continuous_update=False,\n",
    "                orientation='horizontal',\n",
    "                readout=True,\n",
    "                readout_format='i',\n",
    "                slider_color='white',\n",
    "                color='black'\n",
    "        )\n",
    "    \n",
    "    threshold_picker = widgets.FloatSlider(\n",
    "                value=0.5,\n",
    "                min=0,\n",
    "                max=1,\n",
    "                step=0.1,\n",
    "                description='Threshold:',\n",
    "                disabled=False,\n",
    "                continuous_update=False,\n",
    "                orientation='horizontal',\n",
    "                readout=True,\n",
    "                readout_format='.1f',\n",
    "                slider_color='white',\n",
    "                color='black'\n",
    "        )\n",
    "    \n",
    "    event_picker = widgets.Dropdown(\n",
    "            options=[1,2,3],\n",
    "            description='Event Number:',\n",
    "            disabled=False,\n",
    "            button_style='' # 'success', 'info', 'warning', 'danger' or ''\n",
    "        )\n",
    "    \n",
    "    l = widgets.Layout(height='40px', width='800px')\n",
    "    event_text_area = widgets.Textarea(value='TA: height=40px', layout=l)\n",
    "\n",
    "all_events = []\n",
    "usable_events = []\n",
    "usable_control_events = []\n",
    "usable_test_events = []\n",
    "\n",
    "def event_picker_change_handler(change):\n",
    "    event_text_area.value = json.dumps(usable_events[event_picker.value])\n",
    "    \n",
    "# Handle data source change\n",
    "def data_source_change_handler(change):\n",
    "    del all_events[:]\n",
    "    all_events.extend(SplunkFileSource.load_data('../../data/' + data_source_picker.value))\n",
    "\n",
    "    #print(len(loaded_dictionaries))\n",
    "    \n",
    "    minutes = 0\n",
    "    for dict in all_events:\n",
    "        if dict.get('cluster_label') == '1':\n",
    "            minutes = minutes + 1\n",
    "\n",
    "    time_range_picker.value = [1,2]\n",
    "    time_range_picker.min = 1\n",
    "    time_range_picker.max = minutes\n",
    "    \n",
    "    new_time_range_picker.value = [minutes -2, minutes]\n",
    "    new_time_range_picker.min = 1\n",
    "    new_time_range_picker.max = minutes\n",
    "    \n",
    "    time_slider_change_handler(' ')    \n",
    "    \n",
    "def time_slider_change_handler(change):\n",
    "    clear_output()\n",
    "    del usable_events[:]\n",
    "    del usable_control_events[:]\n",
    "    del usable_test_events[:]\n",
    "\n",
    "    minute=0\n",
    "    for dict in all_events:\n",
    "        if dict.get('cluster_label') == '1':\n",
    "            minute = minute + 1\n",
    "        if minute >= time_range_picker.value[0] and minute <= time_range_picker.value[1]:\n",
    "            usable_events.append(dict)\n",
    "            usable_control_events.append([dict.get('_raw'), len(usable_events) - 1, dict.get('cluster_count')])\n",
    "        if minute>= new_time_range_picker.value[0] and minute <= new_time_range_picker.value[0]:\n",
    "            usable_events.append(dict)\n",
    "            usable_test_events.append([dict.get('_raw'), len(usable_events) - 1, dict.get('cluster_count')])\n",
    "            \n",
    "    event_picker.options = [ x for x in range(len(usable_events))] \n",
    "    cluster()\n",
    "    \n",
    "def plot_cluster(dist, km, features):\n",
    "    order_centroids = km.get_centriods()\n",
    "    klusters = km.get_clusters()\n",
    "    tooltips = []\n",
    "    for id in range(len(set(klusters))):\n",
    "        tip = 'cluster = ' + str(id) + '<br>'\n",
    "        for i in order_centroids[id,:15]:\n",
    "            tip = tip + features[i] + '<br>'\n",
    "        tooltips.append(tip)\n",
    "    plot.scatter_plot_groups(dist, klusters, tooltips)\n",
    "\n",
    "    \n",
    "def split(input, length, size):\n",
    "    input.replace('\\n', ' ')\n",
    "    input.replace('\\tat', ' ')\n",
    "    return '<br>'.join([input[start:start + size] for start in range(0, length, size)])\n",
    "\n",
    "def create_combined_scatter_plot(control_events, test_events, labels, clusters, plot_3d=False):\n",
    "    combined_usable_events = []\n",
    "    combined_usable_events.extend(control_events)\n",
    "    combined_usable_events.extend(test_events)\n",
    "    combined_tfidf_vectorizer = TFIDFVectorizer(Tokenizer.default_tokenizer, 1, 1.0)\n",
    "    combined_tfidf_matrix = combined_tfidf_vectorizer.fit_transform(np.array(combined_usable_events)[:,0])\n",
    "\n",
    "    combined_dist = combined_tfidf_vectorizer.get_cosine_dist_matrix(combined_tfidf_matrix)\n",
    "    tooltips = []\n",
    "    #usable_combined_event_counts=[]\n",
    "    usable_control_event_counts = []\n",
    "    usable_test_event_counts = []\n",
    "    for idx, event in enumerate(control_events):\n",
    "        tooltips.append(split(event[0], min(1000, len(event[0])), 100) + '<br> id = ' + str(event[1]) + '<br> cluster = ' + str(clusters[idx]))\n",
    "     \n",
    "    for idx, event in enumerate(test_events):\n",
    "        tooltips.append(split(event[0], min(1000, len(event[0])), 100) + '<br> id = ' + str(event[1]) + '<br> cluster = ' + str(clusters[len(control_events) + idx]))\n",
    "        #usable_combined_event_counts.append(usable_events[event[1]].get('cluster_count'))\n",
    "        #usable_test_event_counts.append(usable_events[event[1]].get('cluster_count'))\n",
    "    \n",
    "    \n",
    "    if plot_3d == False:\n",
    "        plot.scatter_plot_groups(combined_dist, labels, tooltips, ['control', 'test', 'test-anomaly'], ['blue','orange','red'])\n",
    "    else:\n",
    "        combined_values = np.column_stack((combined_dist, np.array(combined_usable_events)[:,2]))\n",
    "        plot.scatter_plot_groups_4d(combined_values, labels, clusters, tooltips, ['blue','orange','red'])\n",
    "\n",
    "\n",
    "    \n",
    "def cluster():\n",
    "        \n",
    "    print('plotting....')\n",
    "    \n",
    "    tfidf_vectorizer = TFIDFVectorizer(Tokenizer.default_tokenizer, 1, 1.0)\n",
    "    \n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(np.array(usable_control_events)[:,0])\n",
    "    \n",
    "    dist = tfidf_vectorizer.get_cosine_dist_matrix(tfidf_matrix)\n",
    "    \n",
    "    plot.scatter_plot(dist, usable_control_events)\n",
    "    \n",
    "    print(\"clustering....\")\n",
    "    kmeans = KmeansCluster(tfidf_matrix, threshold_picker.value)\n",
    "    kmeans.cluster_cosine_threshold()\n",
    "    plot_cluster(dist, kmeans, tfidf_vectorizer.get_feature_names())\n",
    "    \n",
    "    print(\"Detecting new anomaly\")\n",
    "    tfidf_matrix_test = tfidf_vectorizer.transform(np.array(usable_test_events)[:,0])\n",
    "    newAnomDetector = KmeansAnomalyDetector()\n",
    "    predictions = np.array(newAnomDetector.detect_kmeans_anomaly_cosine_dist(tfidf_matrix_test, kmeans, threshold_picker.value))\n",
    "    \n",
    "    \n",
    "    labels = []\n",
    "    klus = kmeans.get_clusters()\n",
    "    \n",
    "    for i in range(len(usable_control_events)):\n",
    "        labels.append(0)\n",
    "    #labels = np.zeros(len(usable_control_events), dtype=np.int))\n",
    "    for p in predictions:\n",
    "        klus.append(p)\n",
    "        if p != -1:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(2)\n",
    "   \n",
    "    \n",
    "    create_combined_scatter_plot(usable_control_events, usable_test_events, labels, klus)\n",
    "\n",
    "\n",
    "    print(\"Detecting existing anomaly\")\n",
    "\n",
    "\n",
    "    control_values = np.column_stack((kmeans.get_clusters(), np.array(usable_control_events)))\n",
    "        \n",
    "    test_values = np.column_stack((predictions, np.array(usable_test_events)))[predictions != -1]\n",
    "    #test_events_fit = np.array(usable_test_events)[predictions != -1]\n",
    "    \n",
    "    control_df = pd.DataFrame(dict(x=control_values[:,0], y=control_values[:,3], \n",
    "                                   label=control_values[:,0], text=control_values[:,1], idx=control_values[:,2]))\n",
    "    test_df = pd.DataFrame(dict(x=test_values[:,0], y=test_values[:,3], \n",
    "                                label=test_values[:,0], text=test_values[:,1], idx=test_values[:,2]))\n",
    "\n",
    "    control_groups = control_df.groupby('label')\n",
    "    test_groups = test_df.groupby('label')\n",
    "    \n",
    "    classifier = IsolationForestClassifier()\n",
    "        \n",
    "    labels_test = [0] * len(usable_events)\n",
    "\n",
    "    #labels_by_cluster = {}\n",
    "    #combined_event_counts = {}\n",
    "    klusters_test = [-1] * len(usable_events)\n",
    "    \n",
    "    for name, group in control_groups:\n",
    "        classifier.fit_transform(str(name), np.column_stack((group.x,group.y)))\n",
    "        #control_values_by_cluster[str(name)] = np.column_stack(np.arange(group.shape[0]),group.y)\n",
    "        #labels_by_cluster[str(name)] = [0] * group.shape[0]\n",
    "    \n",
    "    for name, group in test_groups:\n",
    "        preds = classifier.predict(str(name), np.column_stack((group.x,group.y)))\n",
    "        #control_values_by_cluster[str(name)].append(np.column_stack(np.arange(group.shape[0]),group.y)  )\n",
    "        ids = group.idx.tolist()\n",
    "        for k,pred in enumerate(preds):\n",
    "            if pred == 1:\n",
    "                labels_test[int(ids[k])] = 1\n",
    "                klusters_test[int(ids[k])] = int(name)\n",
    "                #labels_by_cluster[str(name)].append(1)\n",
    "            else:\n",
    "                labels_test[int(ids[k])] = 2\n",
    "                klusters_test[int(ids[k])] = int(name)\n",
    "                #labels_by_cluster[str(name)].append(2)                    \n",
    "                    \n",
    "                    \n",
    "    labels_test = np.array(labels_test)\n",
    "    labels_test = labels_test[np.where(np.array(labels_test) > 0)[0]]\n",
    "    labels = np.concatenate([np.zeros(len(usable_control_events),dtype=np.int),labels_test])\n",
    "    \n",
    "    klusters_test = np.array(klusters_test)\n",
    "    klusters_test = klusters_test[np.where(np.array(klusters_test) > -1)[0]]\n",
    "    klusters = np.concatenate([kmeans.get_clusters(), klusters_test])\n",
    "\n",
    "\n",
    "    print('------')\n",
    "    print(len(labels))\n",
    "    print(len(klusters))\n",
    "    print('-------')\n",
    "    create_combined_scatter_plot(control_values[:,1:4], test_values[:,1:4], labels, klusters, True)\n",
    "\n",
    "    \n",
    "    \n",
    "    #usable_control_event_counts = np.column_stack((dist, usable_combined_event_counts))\n",
    "    #usable_test_event_counts = np.column_stack((dist, usable_combined_event_counts))\n",
    "\n",
    "            \n",
    "    #tooltips = [ str(id) for id in range(set(klusters))]\n",
    "    #tooltips = []\n",
    "        #Cluster_KMeans.scatter_plot(tfidf_matrix,num_clusters,km,np.array(selected_text),terms)\n",
    "        #print(num_clusters)\n",
    "        #print(len(terms))\n",
    "        #print(len(selected_text))\n",
    "        #print(km.score(tfidf_matrix))\n",
    "        #score = len(terms)\n",
    "        #print(score)\n",
    "        #print(min_idf)    \n",
    "        #min_idf = min_idf + 0.01\n",
    "        #if prev_score != 0 and ((prev_score - score)/prev_score) <= 0.05:\n",
    "         #   break\n",
    "        #else:\n",
    "         #   prev_tfidf_vectorizer = tfidf_vectorizer\n",
    "         #   prev_score = score\n",
    "         #   prev_tfidf_matrix = tfidf_matrix\n",
    "         #   prev_terms = terms\n",
    "         #   prev_num_clusters = num_clusters\n",
    "         #   prev_km = km\n",
    "            \n",
    "            \n",
    "    \n",
    "    #tfidf_matrix =  prev_tfidf_matrix\n",
    "    #terms = prev_terms\n",
    "    #tfidf_vectorizer = prev_tfidf_vectorizer\n",
    "    #km, num_clusters = Cluster_KMeans.cluster(tfidf_matrix, np.array(selected_text),threshold_picker.value)\n",
    "    #Cluster_KMeans.scatter_plot(tfidf_matrix,num_clusters,km,np.array(selected_text),terms)    \n",
    "        #print(keep_list)\n",
    "        #print(tfidf_matrix.shape)\n",
    "\n",
    "        #print(tfidf_matrix[np.array(keep_list)].shape)\n",
    "        #print(len(np.array(selected_text)[np.array(keep_list)]))\n",
    "\n",
    "        #selected_text = np.array(selected_text)[np.array(keep_list)]\n",
    "        #print(len(selected_text))\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    #while True:\n",
    "        #print('trying min_idf = ' + str(min_idf))\n",
    "        #tfidf_vectorizer = TFIDF_Generator.make_tfidf_vector(min_idf,max_idf)\n",
    "        #tfidf_matrix, terms = TFIDF_Generator.tfidf_vector_fit_transform(tfidf_vectorizer, np.array(selected_text), True)\n",
    "        #print(terms)\n",
    "        #found = True\n",
    "        #for i in range(tfidf_matrix.shape[0]):\n",
    "            #if np.sum(tfidf_matrix[i,:]) == 0.0:\n",
    "             #   print(i)\n",
    "             #   found = False\n",
    "                \n",
    "        #if found == True:\n",
    "         #   print('min_idf = ' + str(min_idf))\n",
    "         #   break\n",
    "        #else:\n",
    "         #   min_idf = min_idf - 0.01\n",
    "    \n",
    "        #if min_idf < 0.0:\n",
    "         #   print('Something is very wrong. min_idf =  ' + str(min_idf))    \n",
    "\n",
    "create_widgets()\n",
    "\n",
    "    \n",
    "#setup even handlers    \n",
    "data_source_picker.observe(data_source_change_handler, names=\"value\")\n",
    "time_range_picker.observe(time_slider_change_handler, names=\"value\")\n",
    "new_time_range_picker.observe(time_slider_change_handler, names=\"value\")\n",
    "event_picker.observe(event_picker_change_handler, names=\"value\")\n",
    "#threshold_picker.observe(threshold_picker_change_handler, names=\"value\")\n",
    "#intialize\n",
    "data_source_change_handler('')\n",
    "event_picker_change_handler('')\n",
    "\n",
    "# show widgets\n",
    "display(widgets.HBox([data_source_picker]))\n",
    "display(widgets.HBox([time_range_picker, threshold_picker]))\n",
    "display(widgets.HBox([new_time_range_picker]))\n",
    "display(widgets.HBox([event_picker, event_text_area]))\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
