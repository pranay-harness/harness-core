Var jobUrl = concat(Env:baseUrl, "v1/search/jobs")
Var bodyMap = {}
Var:bodyMap.put("query", Env:query)
Var:bodyMap.put("from", Env:startTimeMillis)
Var:bodyMap.put("to", Env:endTimeMillis)
Var job = sync-call(url=Var:jobUrl, header=Env:commonHeaders, body=Var:bodyMap)
Var jobId = extract(Var:job, $.id)
sleep(500)
Var resultsUrl = concat(Env:baseUrl, "v1/search/jobs/", Var:jobId)
Var jobResult = sync-call(url=Var:resultsUrl, header=Env:commonHeaders)
Var jobState = extract(Var:jobResult, $.state)

Var resultGathered = "false"
while Var:resultGathered == "false" {
  if Var:jobState == "FORCE PAUSED" {
    resultGathered = "true"
  }

  if Var:jobState == "DONE GATHERING RESULTS" {
    resultGathered = "true"
  }

  if Var:jobState == "CANCELLED" {
    resultGathered = "true"
  }
  sleep(1000)
}

if Var:jobState == "CANCELLED" {
  throw exception "Serarch job cancelled"
}

Var messageCount = extract(Var:jobResult, $.messageCount)
Var logs = []
Var currentSize = 0;
Var pageSize = 1000;

Var options = {}
Var:options.put("offset", Var:currentSize)
Var:options.put("limit", Var:pageSize )
while currentSize <= messageCount {
  Var:options.put("offset", Var:currentSize)
  Var messageUrl = concat(Env:baseUrl, "v1/search/jobs/", Var:jobId)
  Var messageResults = sync-call(url=Var:resultsUrl, header=Env:commonHeaders, options=Var:options)
  #TODO: parse messages and append
  Var messages = extract(Var:messageResults, $.messages)
  foreach rawLog in Var:messages {
    Var hostname = extract(Var:rawLog, Env:serviceInstanceIdentifier)
    Var log = extract(Var:rawLog, $._raw)
    Var timestamp = extract(Var:rawLog, $._messagetime)
    Var logToReturn = new LogDataRecord(log=Var:log, timestamp=Var:timestamp, host=Var:hostname)
    Var:logs.append(Var:logToReturn)
  }
  currentSize = Var:currentSize + Var:pageSize
}

return Var:logs
